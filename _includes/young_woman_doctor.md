<!-- what motivates us? -->
<h2 id="choices-motivated-value">The woman that wants to be a doctor</h2>
Consider a young woman that **pursues** a career as a doctor because she **looks forward** to *"being the source of somebody's good news"* every day. This involves her placing value on states in which she believes another person has received information from her and labeled it "positive". In order to pursue this career, she needs to **reason** over a *wide range of temporal resolutions* (e.g. short-term and long-term) about **goal-directed** options that will lead her into a **consistent pattern of states** that provide her her desired reward  (telling people good news every day). 

<h3 id="choices-motivated"> How are our choices and actions motivated?</h3>
1. How does she represent this desired "consistent pattern of states"? 
2. How does she reason that particular middle-range options will lead her to this future?
3. How does she coordinate planning at different temporal resolutions? 
4. Does her function for state-value estimation depend on her plan's current temporal resolution? 

In order to accomplish her goals, the young woman must predict action-dependent short- and long-range state-representations, estimate their values, and choose actions accordingly. When predicting state-representations, relevant factors may be dependent on her choice constraints. For example, location may matter for choosing a medical school but not for choosing a class.
<!-- when she applying to medical schools, location may be an important factor whereas when choosing her classes, location may be less important than her specialization of interest.  -->
Thus, being able to create compact but sufficiently expressive representations of distant states composed by already learned hidden variables seems like a necessary ability.
<!-- The woman uses a subset of things that are likey in the future state to represent it. not necessarily the machines she'll use or the tables she'll sit at, or the shoes she'll wear but things important to value estimation. this implies value is places on constituents and a corresponding abstract, lossy state-representation, rather then a full state. -->

<h3 id="value-hidden-variables">How do we represent states and estimate their values?</h3>

1. Does the woman represent states as a composition of hidden variables?
1. When predicting future states, how does she learn **which** latent factors to predict?
<!-- 1. How does she learn to estimate the value of both current and predicted future states? -->
2. Does she impose some sort of structure over the hidden variable composition?
3. How does she learn to place value on a state's hidden variable constituents? This is closely related to the problem of reinforcement learning of **credit assignment**.
<!-- 4. If the value she has for states is a function of what she has previously valued, how is this value transferred both to a state and its constituents? -->
<!-- 5. Is it a question of state-value estimation or hidden-variable-value estimation? If the latter, how do we decompose states into their constituents? -->